<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Algorithms · FrankWolfe.jl</title><meta name="title" content="Algorithms · FrankWolfe.jl"/><meta property="og:title" content="Algorithms · FrankWolfe.jl"/><meta property="twitter:title" content="Algorithms · FrankWolfe.jl"/><meta name="description" content="Documentation for FrankWolfe.jl."/><meta property="og:description" content="Documentation for FrankWolfe.jl."/><meta property="twitter:description" content="Documentation for FrankWolfe.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">FrankWolfe.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../basics/">How does it work?</a></li><li><a class="tocitem" href="../../advanced/">Advanced features</a></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../examples/docs_00_fw_visualized/">Visualization of Frank-Wolfe running on a 2-dimensional polytope</a></li><li><a class="tocitem" href="../../examples/docs_01_mathopt_lmo/">Comparison with MathOptInterface on a Probability Simplex</a></li><li><a class="tocitem" href="../../examples/docs_02_polynomial_regression/">Polynomial Regression</a></li><li><a class="tocitem" href="../../examples/docs_03_matrix_completion/">Matrix Completion</a></li><li><a class="tocitem" href="../../examples/docs_04_rational_opt/">Exact Optimization with Rational Arithmetic</a></li><li><a class="tocitem" href="../../examples/docs_05_blended_cg/">Blended Conditional Gradients</a></li><li><a class="tocitem" href="../../examples/docs_06_spectrahedron/">Spectrahedron</a></li><li><a class="tocitem" href="../../examples/docs_07_shifted_norm_polytopes/">FrankWolfe for scaled, shifted <span>$\ell^1$</span> and <span>$\ell^{\infty}$</span> norm balls</a></li><li><a class="tocitem" href="../../examples/docs_08_callback_and_tracking/">Tracking, counters and custom callbacks for Frank Wolfe</a></li><li><a class="tocitem" href="../../examples/docs_09_extra_vertex_storage/">Extra-lazification</a></li><li><a class="tocitem" href="../../examples/docs_10_alternating_methods/">Alternating methods</a></li><li><a class="tocitem" href="../../examples/docs_11_block_coordinate_fw/">Block-Coordinate Frank-Wolfe and Block-Vectors</a></li><li><a class="tocitem" href="../../examples/docs_12_quadratic_symmetric/">Accelerations for quadratic functions and symmetric problems</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox" checked/><label class="tocitem" for="menuitem-5"><span class="docs-label">API reference</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../0_reference/">API Reference</a></li><li class="is-active"><a class="tocitem" href>Algorithms</a><ul class="internal"><li><a class="tocitem" href="#Standard-algorithms"><span>Standard algorithms</span></a></li><li><a class="tocitem" href="#Active-set-based-methods"><span>Active-set based methods</span></a></li><li><a class="tocitem" href="#Alternating-Methods"><span>Alternating Methods</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li><li><a class="tocitem" href="../2_lmo/">Linear Minimization Oracles</a></li><li><a class="tocitem" href="../3_backend/">Utilities and data structures</a></li><li><a class="tocitem" href="../4_linesearch/">Line search and step size settings</a></li><li><a class="tocitem" href="../5_gradient_descent/">Adaptive Proximal Gradient Descent Methods</a></li></ul></li><li><a class="tocitem" href="../../contributing/">Contributing</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API reference</a></li><li class="is-active"><a href>Algorithms</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Algorithms</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ZIB-IOL/FrankWolfe.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/master/docs/src/reference/1_algorithms.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Algorithms"><a class="docs-heading-anchor" href="#Algorithms">Algorithms</a><a id="Algorithms-1"></a><a class="docs-heading-anchor-permalink" href="#Algorithms" title="Permalink"></a></h1><p>This section contains all main algorithms of the package. These are the ones typical users will call.</p><p>The typical signature for these algorithms is:</p><pre><code class="language-julia hljs">my_algorithm(f, grad!, lmo, x0)</code></pre><h2 id="Standard-algorithms"><a class="docs-heading-anchor" href="#Standard-algorithms">Standard algorithms</a><a id="Standard-algorithms-1"></a><a class="docs-heading-anchor-permalink" href="#Standard-algorithms" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.frank_wolfe-NTuple{4, Any}" href="#FrankWolfe.frank_wolfe-NTuple{4, Any}"><code>FrankWolfe.frank_wolfe</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">frank_wolfe(f, grad!, lmo, x0; kwargs...)</code></pre><p>Simplest form of the Frank-Wolfe algorithm.</p><p><strong>Common arguments</strong></p><p>These positional arguments are common to most Frank-Wolfe variants:</p><ul><li><code>f</code>: a function <code>f(x)</code> computing the value of the objective to minimize at point <code>x</code></li><li><code>grad!</code>: a function <code>grad!(g, x)</code> overwriting <code>g</code> with the gradient of <code>f</code> at point <code>x</code></li><li><code>lmo</code>: a linear minimization oracle, subtyping <a href="../2_lmo/#FrankWolfe.LinearMinimizationOracle"><code>LinearMinimizationOracle</code></a></li><li><code>x0</code>: a starting point for the optimization (will be modified in-place for <code>frank_wolfe</code> with <code>InplaceEmphasis</code>)</li></ul><p><strong>Common keyword arguments</strong></p><p>These keyword arguments are common to most Frank-Wolfe variants.</p><div class="admonition is-warning" id="Warning-8d349c160860f6b8"><header class="admonition-header">Warning<a class="admonition-anchor" href="#Warning-8d349c160860f6b8" title="Permalink"></a></header><div class="admonition-body"><p>The current variant may have additional keyword arguments, documented elsewhere, or it may only use a subset of the ones listed below. The default values of these arguments may also vary between variants, and thus are not part of the public API.</p></div></div><ul><li><code>line_search::LineSearchMethod</code>: an object specifying the line search and its parameters (see <a href="../4_linesearch/#FrankWolfe.LineSearchMethod"><code>LineSearchMethod</code></a>)</li><li><code>momentum::Union{Real,Nothing}=nothing</code>: constant momentum to apply to the gradient</li><li><code>epsilon::Real</code>: absolute dual gap threshold at which the algorithm is interrupted</li><li><code>max_iteration::Integer</code>: maximum number of iterations after which the algorithm is interrupted</li><li><code>print_iter::Integer</code>: interval between two consecutive log prints, expressed in number of iterations</li><li><code>trajectory::Bool=false</code>: whether to record the trajectory of algorithm states (through callbacks)</li><li><code>verbose::Bool</code>: whether to print periodic logs (through callbacks)</li><li><code>memory_mode::MemoryEmphasis</code>: an object dictating whether the algorithm operates in-place or out-of-place (see <a href="@ref"><code>MemoryEmphasis</code></a>)</li><li><code>gradient=nothing</code>: pre-allocated container for the gradient</li><li><code>callback=nothing</code>: function called on a <a href="../3_backend/#FrankWolfe.CallbackState"><code>CallbackState</code></a> at each iteration</li><li><code>traj_data=[]</code>: pre-allocated storage for the trajectory of algorithm states</li><li><code>timeout::Real=Inf</code>: maximum time after which the algorithm is interrupted (in nanoseconds)</li><li><code>linesearch_workspace=nothing</code>: pre-allocated workspace for the line search </li><li><code>dual_gap_compute_frequency::Integer=1</code>: frequency of dual gap computation, </li></ul><p><strong>Return</strong></p><p>Returns a tuple <code>(x, v, primal, dual_gap, traj_data)</code> with:</p><ul><li><code>x</code>: the final iterate</li><li><code>v</code>: the last vertex from the linear minimization oracle</li><li><code>primal</code>: the final primal value <code>f(x)</code></li><li><code>dual_gap</code>: the final Frank-Wolfe gap</li><li><code>traj_data</code>: a vector of trajectory information, each element being the output of <a href="@ref"><code>callback_state</code></a>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/fw_algorithms.jl#L2-L12">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.lazified_conditional_gradient-NTuple{4, Any}" href="#FrankWolfe.lazified_conditional_gradient-NTuple{4, Any}"><code>FrankWolfe.lazified_conditional_gradient</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">lazified_conditional_gradient(f, grad!, lmo_base, x0; kwargs...)</code></pre><p>Similar to <a href="#FrankWolfe.frank_wolfe-NTuple{4, Any}"><code>FrankWolfe.frank_wolfe</code></a> but lazyfying the LMO: each call is stored in a cache, which is looked up first for a good-enough direction. The cache used is a <a href="../2_lmo/#FrankWolfe.MultiCacheLMO"><code>FrankWolfe.MultiCacheLMO</code></a> or a <a href="../2_lmo/#FrankWolfe.VectorCacheLMO"><code>FrankWolfe.VectorCacheLMO</code></a> depending on whether the provided <code>cache_size</code> option is finite.</p><p><strong>Common arguments</strong></p><p>These positional arguments are common to most Frank-Wolfe variants:</p><ul><li><code>f</code>: a function <code>f(x)</code> computing the value of the objective to minimize at point <code>x</code></li><li><code>grad!</code>: a function <code>grad!(g, x)</code> overwriting <code>g</code> with the gradient of <code>f</code> at point <code>x</code></li><li><code>lmo</code>: a linear minimization oracle, subtyping <a href="../2_lmo/#FrankWolfe.LinearMinimizationOracle"><code>LinearMinimizationOracle</code></a></li><li><code>x0</code>: a starting point for the optimization (will be modified in-place for <code>frank_wolfe</code> with <code>InplaceEmphasis</code>)</li></ul><p><strong>Common keyword arguments</strong></p><p>These keyword arguments are common to most Frank-Wolfe variants.</p><div class="admonition is-warning" id="Warning-8d349c160860f6b8"><header class="admonition-header">Warning<a class="admonition-anchor" href="#Warning-8d349c160860f6b8" title="Permalink"></a></header><div class="admonition-body"><p>The current variant may have additional keyword arguments, documented elsewhere, or it may only use a subset of the ones listed below. The default values of these arguments may also vary between variants, and thus are not part of the public API.</p></div></div><ul><li><code>line_search::LineSearchMethod</code>: an object specifying the line search and its parameters (see <a href="../4_linesearch/#FrankWolfe.LineSearchMethod"><code>LineSearchMethod</code></a>)</li><li><code>momentum::Union{Real,Nothing}=nothing</code>: constant momentum to apply to the gradient</li><li><code>epsilon::Real</code>: absolute dual gap threshold at which the algorithm is interrupted</li><li><code>max_iteration::Integer</code>: maximum number of iterations after which the algorithm is interrupted</li><li><code>print_iter::Integer</code>: interval between two consecutive log prints, expressed in number of iterations</li><li><code>trajectory::Bool=false</code>: whether to record the trajectory of algorithm states (through callbacks)</li><li><code>verbose::Bool</code>: whether to print periodic logs (through callbacks)</li><li><code>memory_mode::MemoryEmphasis</code>: an object dictating whether the algorithm operates in-place or out-of-place (see <a href="@ref"><code>MemoryEmphasis</code></a>)</li><li><code>gradient=nothing</code>: pre-allocated container for the gradient</li><li><code>callback=nothing</code>: function called on a <a href="../3_backend/#FrankWolfe.CallbackState"><code>CallbackState</code></a> at each iteration</li><li><code>traj_data=[]</code>: pre-allocated storage for the trajectory of algorithm states</li><li><code>timeout::Real=Inf</code>: maximum time after which the algorithm is interrupted (in nanoseconds)</li><li><code>linesearch_workspace=nothing</code>: pre-allocated workspace for the line search </li><li><code>dual_gap_compute_frequency::Integer=1</code>: frequency of dual gap computation, </li></ul><p><strong>Return</strong></p><p>Returns a tuple <code>(x, v, primal, dual_gap, traj_data)</code> with:</p><ul><li><code>x</code>: the final iterate</li><li><code>v</code>: the last vertex from the linear minimization oracle</li><li><code>primal</code>: the final primal value <code>f(x)</code></li><li><code>dual_gap</code>: the final Frank-Wolfe gap</li><li><code>traj_data</code>: a vector of trajectory information, each element being the output of <a href="@ref"><code>callback_state</code></a>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/fw_algorithms.jl#L244-L257">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.stochastic_frank_wolfe-Tuple{FrankWolfe.AbstractStochasticObjective, Any, Any}" href="#FrankWolfe.stochastic_frank_wolfe-Tuple{FrankWolfe.AbstractStochasticObjective, Any, Any}"><code>FrankWolfe.stochastic_frank_wolfe</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">stochastic_frank_wolfe(f::StochasticObjective, lmo, x0; kwargs...)</code></pre><p>Stochastic version of Frank-Wolfe, evaluates the objective and gradient stochastically, implemented through the <a href="../3_backend/#FrankWolfe.StochasticObjective"><code>FrankWolfe.StochasticObjective</code></a> interface.</p><p><strong>Common arguments</strong></p><p>These positional arguments are common to most Frank-Wolfe variants:</p><ul><li><code>f</code>: a function <code>f(x)</code> computing the value of the objective to minimize at point <code>x</code></li><li><code>grad!</code>: a function <code>grad!(g, x)</code> overwriting <code>g</code> with the gradient of <code>f</code> at point <code>x</code></li><li><code>lmo</code>: a linear minimization oracle, subtyping <a href="../2_lmo/#FrankWolfe.LinearMinimizationOracle"><code>LinearMinimizationOracle</code></a></li><li><code>x0</code>: a starting point for the optimization (will be modified in-place for <code>frank_wolfe</code> with <code>InplaceEmphasis</code>)</li></ul><p><strong>Common keyword arguments</strong></p><p>These keyword arguments are common to most Frank-Wolfe variants.</p><div class="admonition is-warning" id="Warning-8d349c160860f6b8"><header class="admonition-header">Warning<a class="admonition-anchor" href="#Warning-8d349c160860f6b8" title="Permalink"></a></header><div class="admonition-body"><p>The current variant may have additional keyword arguments, documented elsewhere, or it may only use a subset of the ones listed below. The default values of these arguments may also vary between variants, and thus are not part of the public API.</p></div></div><ul><li><code>line_search::LineSearchMethod</code>: an object specifying the line search and its parameters (see <a href="../4_linesearch/#FrankWolfe.LineSearchMethod"><code>LineSearchMethod</code></a>)</li><li><code>momentum::Union{Real,Nothing}=nothing</code>: constant momentum to apply to the gradient</li><li><code>epsilon::Real</code>: absolute dual gap threshold at which the algorithm is interrupted</li><li><code>max_iteration::Integer</code>: maximum number of iterations after which the algorithm is interrupted</li><li><code>print_iter::Integer</code>: interval between two consecutive log prints, expressed in number of iterations</li><li><code>trajectory::Bool=false</code>: whether to record the trajectory of algorithm states (through callbacks)</li><li><code>verbose::Bool</code>: whether to print periodic logs (through callbacks)</li><li><code>memory_mode::MemoryEmphasis</code>: an object dictating whether the algorithm operates in-place or out-of-place (see <a href="@ref"><code>MemoryEmphasis</code></a>)</li><li><code>gradient=nothing</code>: pre-allocated container for the gradient</li><li><code>callback=nothing</code>: function called on a <a href="../3_backend/#FrankWolfe.CallbackState"><code>CallbackState</code></a> at each iteration</li><li><code>traj_data=[]</code>: pre-allocated storage for the trajectory of algorithm states</li><li><code>timeout::Real=Inf</code>: maximum time after which the algorithm is interrupted (in nanoseconds)</li><li><code>linesearch_workspace=nothing</code>: pre-allocated workspace for the line search </li><li><code>dual_gap_compute_frequency::Integer=1</code>: frequency of dual gap computation, </li></ul><p><strong>Specific keyword arguments</strong></p><p>Keyword arguments include <code>batch_size</code> to pass a fixed <code>batch_size</code> or a <code>batch_iterator</code> implementing <code>batch_size = FrankWolfe.batchsize_iterate(batch_iterator)</code> for algorithms like Variance-reduced and projection-free stochastic optimization, E Hazan, H Luo, 2016.</p><p>Similarly, a constant <code>momentum</code> can be passed or replaced by a <code>momentum_iterator</code> implementing <code>momentum = FrankWolfe.momentum_iterate(momentum_iterator)</code>.</p><p>The keyword <code>use_full_evaluation</code> set to true allows the algorithm to compute the deterministic primal value and FW gap.</p><p><strong>Return</strong></p><p>Returns a tuple <code>(x, v, primal, dual_gap, traj_data)</code> with:</p><ul><li><code>x</code>: the final iterate</li><li><code>v</code>: the last vertex from the linear minimization oracle</li><li><code>primal</code>: the final primal value <code>f(x)</code></li><li><code>dual_gap</code>: the final Frank-Wolfe gap</li><li><code>traj_data</code>: a vector of trajectory information, each element being the output of <a href="@ref"><code>callback_state</code></a>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/fw_algorithms.jl#L483-L506">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.block_coordinate_frank_wolfe" href="#FrankWolfe.block_coordinate_frank_wolfe"><code>FrankWolfe.block_coordinate_frank_wolfe</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">block_coordinate_frank_wolfe(f, grad!, lmo::ProductLMO{N}, x0; kwargs...) where {N}</code></pre><p>Block-coordinate version of the Frank-Wolfe algorithm. Minimizes objective <code>f</code> over the product of feasible domains specified by the <code>lmo</code>. The optional argument the <code>update_order</code> is of type <a href="../3_backend/#FrankWolfe.BlockCoordinateUpdateOrder"><code>FrankWolfe.BlockCoordinateUpdateOrder</code></a> and controls the order in which the blocks are updated. The argument <code>update_step</code> is a single instance or tuple of <a href="../3_backend/#FrankWolfe.UpdateStep"><code>FrankWolfe.UpdateStep</code></a> and defines which FW-algorithms to use to update the iterates in the different blocks.</p><p>See <a href="https://arxiv.org/abs/1207.4747">S. Lacoste-Julien, M. Jaggi, M. Schmidt, and P. Pletscher 2013</a> and <a href="https://arxiv.org/abs/1502.03716">A. Beck, E. Pauwels and S. Sabach 2015</a> for more details about Block-Coordinate Frank-Wolfe.</p><p><strong>Common arguments</strong></p><p>These positional arguments are common to most Frank-Wolfe variants:</p><ul><li><code>f</code>: a function <code>f(x)</code> computing the value of the objective to minimize at point <code>x</code></li><li><code>grad!</code>: a function <code>grad!(g, x)</code> overwriting <code>g</code> with the gradient of <code>f</code> at point <code>x</code></li><li><code>lmo</code>: a linear minimization oracle, subtyping <a href="../2_lmo/#FrankWolfe.LinearMinimizationOracle"><code>LinearMinimizationOracle</code></a></li><li><code>x0</code>: a starting point for the optimization (will be modified in-place for <code>frank_wolfe</code> with <code>InplaceEmphasis</code>)</li></ul><p><strong>Common keyword arguments</strong></p><p>These keyword arguments are common to most Frank-Wolfe variants.</p><div class="admonition is-warning" id="Warning-8d349c160860f6b8"><header class="admonition-header">Warning<a class="admonition-anchor" href="#Warning-8d349c160860f6b8" title="Permalink"></a></header><div class="admonition-body"><p>The current variant may have additional keyword arguments, documented elsewhere, or it may only use a subset of the ones listed below. The default values of these arguments may also vary between variants, and thus are not part of the public API.</p></div></div><ul><li><code>line_search::LineSearchMethod</code>: an object specifying the line search and its parameters (see <a href="../4_linesearch/#FrankWolfe.LineSearchMethod"><code>LineSearchMethod</code></a>)</li><li><code>momentum::Union{Real,Nothing}=nothing</code>: constant momentum to apply to the gradient</li><li><code>epsilon::Real</code>: absolute dual gap threshold at which the algorithm is interrupted</li><li><code>max_iteration::Integer</code>: maximum number of iterations after which the algorithm is interrupted</li><li><code>print_iter::Integer</code>: interval between two consecutive log prints, expressed in number of iterations</li><li><code>trajectory::Bool=false</code>: whether to record the trajectory of algorithm states (through callbacks)</li><li><code>verbose::Bool</code>: whether to print periodic logs (through callbacks)</li><li><code>memory_mode::MemoryEmphasis</code>: an object dictating whether the algorithm operates in-place or out-of-place (see <a href="@ref"><code>MemoryEmphasis</code></a>)</li><li><code>gradient=nothing</code>: pre-allocated container for the gradient</li><li><code>callback=nothing</code>: function called on a <a href="../3_backend/#FrankWolfe.CallbackState"><code>CallbackState</code></a> at each iteration</li><li><code>traj_data=[]</code>: pre-allocated storage for the trajectory of algorithm states</li><li><code>timeout::Real=Inf</code>: maximum time after which the algorithm is interrupted (in nanoseconds)</li><li><code>linesearch_workspace=nothing</code>: pre-allocated workspace for the line search </li><li><code>dual_gap_compute_frequency::Integer=1</code>: frequency of dual gap computation, </li></ul><p><strong>Return</strong></p><p>The method returns a tuple <code>(x, v, primal, dual_gap, traj_data)</code> with:</p><ul><li><code>x</code> cartesian product of final iterates</li><li><code>v</code> cartesian product of last vertices of the LMOs</li><li><code>primal</code> primal value <code>f(x)</code></li><li><code>dual_gap</code> final Frank-Wolfe gap</li><li><code>traj_data</code> vector of trajectory information.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/block_coordinate_algorithms.jl#L467-L490">source</a></section></article><h2 id="Active-set-based-methods"><a class="docs-heading-anchor" href="#Active-set-based-methods">Active-set based methods</a><a id="Active-set-based-methods-1"></a><a class="docs-heading-anchor-permalink" href="#Active-set-based-methods" title="Permalink"></a></h2><p>The following algorithms maintain the representation of the iterates as a convex combination of vertices.</p><h3 id="Away-step"><a class="docs-heading-anchor" href="#Away-step">Away-step</a><a id="Away-step-1"></a><a class="docs-heading-anchor-permalink" href="#Away-step" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.away_frank_wolfe-NTuple{4, Any}" href="#FrankWolfe.away_frank_wolfe-NTuple{4, Any}"><code>FrankWolfe.away_frank_wolfe</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">away_frank_wolfe(f, grad!, lmo, x0; kwargs...)</code></pre><p>Frank-Wolfe with away steps. The algorithm maintains the current iterate as a convex combination of vertices in the <a href="../3_backend/#FrankWolfe.ActiveSet"><code>FrankWolfe.ActiveSet</code></a> data structure. See <a href="https://arxiv.org/abs/2104.06675">M. Besançon, A. Carderera and S. Pokutta 2021</a> for illustrations of away steps.</p><p><strong>Common arguments</strong></p><p>These positional arguments are common to most Frank-Wolfe variants:</p><ul><li><code>f</code>: a function <code>f(x)</code> computing the value of the objective to minimize at point <code>x</code></li><li><code>grad!</code>: a function <code>grad!(g, x)</code> overwriting <code>g</code> with the gradient of <code>f</code> at point <code>x</code></li><li><code>lmo</code>: a linear minimization oracle, subtyping <a href="../2_lmo/#FrankWolfe.LinearMinimizationOracle"><code>LinearMinimizationOracle</code></a></li><li><code>x0</code>: a starting point for the optimization (will be modified in-place for <code>frank_wolfe</code> with <code>InplaceEmphasis</code>)</li></ul><p><strong>Common keyword arguments</strong></p><p>These keyword arguments are common to most Frank-Wolfe variants.</p><div class="admonition is-warning" id="Warning-8d349c160860f6b8"><header class="admonition-header">Warning<a class="admonition-anchor" href="#Warning-8d349c160860f6b8" title="Permalink"></a></header><div class="admonition-body"><p>The current variant may have additional keyword arguments, documented elsewhere, or it may only use a subset of the ones listed below. The default values of these arguments may also vary between variants, and thus are not part of the public API.</p></div></div><ul><li><code>line_search::LineSearchMethod</code>: an object specifying the line search and its parameters (see <a href="../4_linesearch/#FrankWolfe.LineSearchMethod"><code>LineSearchMethod</code></a>)</li><li><code>momentum::Union{Real,Nothing}=nothing</code>: constant momentum to apply to the gradient</li><li><code>epsilon::Real</code>: absolute dual gap threshold at which the algorithm is interrupted</li><li><code>max_iteration::Integer</code>: maximum number of iterations after which the algorithm is interrupted</li><li><code>print_iter::Integer</code>: interval between two consecutive log prints, expressed in number of iterations</li><li><code>trajectory::Bool=false</code>: whether to record the trajectory of algorithm states (through callbacks)</li><li><code>verbose::Bool</code>: whether to print periodic logs (through callbacks)</li><li><code>memory_mode::MemoryEmphasis</code>: an object dictating whether the algorithm operates in-place or out-of-place (see <a href="@ref"><code>MemoryEmphasis</code></a>)</li><li><code>gradient=nothing</code>: pre-allocated container for the gradient</li><li><code>callback=nothing</code>: function called on a <a href="../3_backend/#FrankWolfe.CallbackState"><code>CallbackState</code></a> at each iteration</li><li><code>traj_data=[]</code>: pre-allocated storage for the trajectory of algorithm states</li><li><code>timeout::Real=Inf</code>: maximum time after which the algorithm is interrupted (in nanoseconds)</li><li><code>linesearch_workspace=nothing</code>: pre-allocated workspace for the line search </li><li><code>dual_gap_compute_frequency::Integer=1</code>: frequency of dual gap computation, </li></ul><p><strong>Return</strong></p><p>Returns a tuple <code>(x, v, primal, dual_gap, traj_data, active_set)</code> with:</p><ul><li><code>x</code>: the final iterate</li><li><code>v</code>: the last vertex from the linear minimization oracle</li><li><code>primal</code>: the final primal value <code>f(x)</code></li><li><code>dual_gap</code>: the final Frank-Wolfe gap</li><li><code>traj_data</code>: a vector of trajectory information, each element being the output of <a href="@ref"><code>callback_state</code></a>.</li><li><code>active_set</code>: the computed active set of vertices, of which the solution is a convex combination</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/afw.jl#L2-L15">source</a></section></article><h3 id="Pairwise-Frank-Wolfe"><a class="docs-heading-anchor" href="#Pairwise-Frank-Wolfe">Pairwise Frank-Wolfe</a><a id="Pairwise-Frank-Wolfe-1"></a><a class="docs-heading-anchor-permalink" href="#Pairwise-Frank-Wolfe" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.blended_pairwise_conditional_gradient-NTuple{4, Any}" href="#FrankWolfe.blended_pairwise_conditional_gradient-NTuple{4, Any}"><code>FrankWolfe.blended_pairwise_conditional_gradient</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">blended_pairwise_conditional_gradient(f, grad!, lmo, x0; kwargs...)</code></pre><p>Implements the BPCG algorithm from <a href="https://arxiv.org/abs/2110.12650">Tsuji, Tanaka, Pokutta (2021)</a>. The method uses an active set of current vertices. Unlike away-step, it transfers weight from an away vertex to another vertex of the active set.</p><p><strong>Common arguments</strong></p><p>These positional arguments are common to most Frank-Wolfe variants:</p><ul><li><code>f</code>: a function <code>f(x)</code> computing the value of the objective to minimize at point <code>x</code></li><li><code>grad!</code>: a function <code>grad!(g, x)</code> overwriting <code>g</code> with the gradient of <code>f</code> at point <code>x</code></li><li><code>lmo</code>: a linear minimization oracle, subtyping <a href="../2_lmo/#FrankWolfe.LinearMinimizationOracle"><code>LinearMinimizationOracle</code></a></li><li><code>x0</code>: a starting point for the optimization (will be modified in-place for <code>frank_wolfe</code> with <code>InplaceEmphasis</code>)</li></ul><p><strong>Common keyword arguments</strong></p><p>These keyword arguments are common to most Frank-Wolfe variants.</p><div class="admonition is-warning" id="Warning-8d349c160860f6b8"><header class="admonition-header">Warning<a class="admonition-anchor" href="#Warning-8d349c160860f6b8" title="Permalink"></a></header><div class="admonition-body"><p>The current variant may have additional keyword arguments, documented elsewhere, or it may only use a subset of the ones listed below. The default values of these arguments may also vary between variants, and thus are not part of the public API.</p></div></div><ul><li><code>line_search::LineSearchMethod</code>: an object specifying the line search and its parameters (see <a href="../4_linesearch/#FrankWolfe.LineSearchMethod"><code>LineSearchMethod</code></a>)</li><li><code>momentum::Union{Real,Nothing}=nothing</code>: constant momentum to apply to the gradient</li><li><code>epsilon::Real</code>: absolute dual gap threshold at which the algorithm is interrupted</li><li><code>max_iteration::Integer</code>: maximum number of iterations after which the algorithm is interrupted</li><li><code>print_iter::Integer</code>: interval between two consecutive log prints, expressed in number of iterations</li><li><code>trajectory::Bool=false</code>: whether to record the trajectory of algorithm states (through callbacks)</li><li><code>verbose::Bool</code>: whether to print periodic logs (through callbacks)</li><li><code>memory_mode::MemoryEmphasis</code>: an object dictating whether the algorithm operates in-place or out-of-place (see <a href="@ref"><code>MemoryEmphasis</code></a>)</li><li><code>gradient=nothing</code>: pre-allocated container for the gradient</li><li><code>callback=nothing</code>: function called on a <a href="../3_backend/#FrankWolfe.CallbackState"><code>CallbackState</code></a> at each iteration</li><li><code>traj_data=[]</code>: pre-allocated storage for the trajectory of algorithm states</li><li><code>timeout::Real=Inf</code>: maximum time after which the algorithm is interrupted (in nanoseconds)</li><li><code>linesearch_workspace=nothing</code>: pre-allocated workspace for the line search </li><li><code>dual_gap_compute_frequency::Integer=1</code>: frequency of dual gap computation, </li></ul><p><strong>Return</strong></p><p>Returns a tuple <code>(x, v, primal, dual_gap, traj_data, active_set)</code> with:</p><ul><li><code>x</code>: the final iterate</li><li><code>v</code>: the last vertex from the linear minimization oracle</li><li><code>primal</code>: the final primal value <code>f(x)</code></li><li><code>dual_gap</code>: the final Frank-Wolfe gap</li><li><code>traj_data</code>: a vector of trajectory information, each element being the output of <a href="@ref"><code>callback_state</code></a>.</li><li><code>active_set</code>: the computed active set of vertices, of which the solution is a convex combination</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/blended_pairwise.jl#L1-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.blended_pairwise_conditional_gradient-Union{Tuple{R}, Tuple{AT}, Tuple{Any, Any, Any, FrankWolfe.AbstractActiveSet{AT, R, IT} where IT}} where {AT, R}" href="#FrankWolfe.blended_pairwise_conditional_gradient-Union{Tuple{R}, Tuple{AT}, Tuple{Any, Any, Any, FrankWolfe.AbstractActiveSet{AT, R, IT} where IT}} where {AT, R}"><code>FrankWolfe.blended_pairwise_conditional_gradient</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">blended_pairwise_conditional_gradient(f, grad!, lmo, active_set::AbstractActiveSet; kwargs...)</code></pre><p>Warm-starts BPCG with a pre-defined <code>active_set</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/blended_pairwise.jl#L71-L75">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.pairwise_frank_wolfe-NTuple{4, Any}" href="#FrankWolfe.pairwise_frank_wolfe-NTuple{4, Any}"><code>FrankWolfe.pairwise_frank_wolfe</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">pairwise_frank_wolfe(f, grad!, lmo, x0; kwargs...)</code></pre><p>Frank-Wolfe with pairwise steps. The algorithm maintains the current iterate as a convex combination of vertices in the <a href="../3_backend/#FrankWolfe.ActiveSet"><code>FrankWolfe.ActiveSet</code></a> data structure. See <a href="https://arxiv.org/abs/2104.06675">M. Besançon, A. Carderera and S. Pokutta 2021</a> for illustrations of away steps.  Unlike away-step, it transfers weight from an away vertex to another vertex.</p><p><strong>Common arguments</strong></p><p>These positional arguments are common to most Frank-Wolfe variants:</p><ul><li><code>f</code>: a function <code>f(x)</code> computing the value of the objective to minimize at point <code>x</code></li><li><code>grad!</code>: a function <code>grad!(g, x)</code> overwriting <code>g</code> with the gradient of <code>f</code> at point <code>x</code></li><li><code>lmo</code>: a linear minimization oracle, subtyping <a href="../2_lmo/#FrankWolfe.LinearMinimizationOracle"><code>LinearMinimizationOracle</code></a></li><li><code>x0</code>: a starting point for the optimization (will be modified in-place for <code>frank_wolfe</code> with <code>InplaceEmphasis</code>)</li></ul><p><strong>Common keyword arguments</strong></p><p>These keyword arguments are common to most Frank-Wolfe variants.</p><div class="admonition is-warning" id="Warning-8d349c160860f6b8"><header class="admonition-header">Warning<a class="admonition-anchor" href="#Warning-8d349c160860f6b8" title="Permalink"></a></header><div class="admonition-body"><p>The current variant may have additional keyword arguments, documented elsewhere, or it may only use a subset of the ones listed below. The default values of these arguments may also vary between variants, and thus are not part of the public API.</p></div></div><ul><li><code>line_search::LineSearchMethod</code>: an object specifying the line search and its parameters (see <a href="../4_linesearch/#FrankWolfe.LineSearchMethod"><code>LineSearchMethod</code></a>)</li><li><code>momentum::Union{Real,Nothing}=nothing</code>: constant momentum to apply to the gradient</li><li><code>epsilon::Real</code>: absolute dual gap threshold at which the algorithm is interrupted</li><li><code>max_iteration::Integer</code>: maximum number of iterations after which the algorithm is interrupted</li><li><code>print_iter::Integer</code>: interval between two consecutive log prints, expressed in number of iterations</li><li><code>trajectory::Bool=false</code>: whether to record the trajectory of algorithm states (through callbacks)</li><li><code>verbose::Bool</code>: whether to print periodic logs (through callbacks)</li><li><code>memory_mode::MemoryEmphasis</code>: an object dictating whether the algorithm operates in-place or out-of-place (see <a href="@ref"><code>MemoryEmphasis</code></a>)</li><li><code>gradient=nothing</code>: pre-allocated container for the gradient</li><li><code>callback=nothing</code>: function called on a <a href="../3_backend/#FrankWolfe.CallbackState"><code>CallbackState</code></a> at each iteration</li><li><code>traj_data=[]</code>: pre-allocated storage for the trajectory of algorithm states</li><li><code>timeout::Real=Inf</code>: maximum time after which the algorithm is interrupted (in nanoseconds)</li><li><code>linesearch_workspace=nothing</code>: pre-allocated workspace for the line search </li><li><code>dual_gap_compute_frequency::Integer=1</code>: frequency of dual gap computation, </li></ul><p><strong>Return</strong></p><p>Returns a tuple <code>(x, v, primal, dual_gap, traj_data, active_set)</code> with:</p><ul><li><code>x</code>: the final iterate</li><li><code>v</code>: the last vertex from the linear minimization oracle</li><li><code>primal</code>: the final primal value <code>f(x)</code></li><li><code>dual_gap</code>: the final Frank-Wolfe gap</li><li><code>traj_data</code>: a vector of trajectory information, each element being the output of <a href="@ref"><code>callback_state</code></a>.</li><li><code>active_set</code>: the computed active set of vertices, of which the solution is a convex combination</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/pairwise.jl#L2-L16">source</a></section></article><h3 id="Blended-Conditional-Gradient"><a class="docs-heading-anchor" href="#Blended-Conditional-Gradient">Blended Conditional Gradient</a><a id="Blended-Conditional-Gradient-1"></a><a class="docs-heading-anchor-permalink" href="#Blended-Conditional-Gradient" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.accelerated_simplex_gradient_descent_over_probability_simplex-Tuple{Any, Any, Any, Any, Any, Any, FrankWolfe.AbstractActiveSet}" href="#FrankWolfe.accelerated_simplex_gradient_descent_over_probability_simplex-Tuple{Any, Any, Any, Any, Any, Any, FrankWolfe.AbstractActiveSet}"><code>FrankWolfe.accelerated_simplex_gradient_descent_over_probability_simplex</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">accelerated_simplex_gradient_descent_over_probability_simplex</code></pre><p>Minimizes an objective function over the unit probability simplex until the Strong-Wolfe gap is below tolerance using Nesterov&#39;s accelerated gradient descent.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/blended_cg.jl#L701-L707">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.blended_conditional_gradient-NTuple{4, Any}" href="#FrankWolfe.blended_conditional_gradient-NTuple{4, Any}"><code>FrankWolfe.blended_conditional_gradient</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">blended_conditional_gradient(f, grad!, lmo, x0; kwargs...)</code></pre><p>Entry point for the Blended Conditional Gradient algorithm. See Braun, Gábor, et al. &quot;Blended conditonal gradients&quot; ICML 2019. The method works on an active set like <a href="#FrankWolfe.away_frank_wolfe-NTuple{4, Any}"><code>FrankWolfe.away_frank_wolfe</code></a>, performing gradient descent over the convex hull of active vertices, removing vertices when their weight drops to 0 and adding new vertices by calling the linear oracle in a lazy fashion.</p><p><strong>Common arguments</strong></p><p>These positional arguments are common to most Frank-Wolfe variants:</p><ul><li><code>f</code>: a function <code>f(x)</code> computing the value of the objective to minimize at point <code>x</code></li><li><code>grad!</code>: a function <code>grad!(g, x)</code> overwriting <code>g</code> with the gradient of <code>f</code> at point <code>x</code></li><li><code>lmo</code>: a linear minimization oracle, subtyping <a href="../2_lmo/#FrankWolfe.LinearMinimizationOracle"><code>LinearMinimizationOracle</code></a></li><li><code>x0</code>: a starting point for the optimization (will be modified in-place for <code>frank_wolfe</code> with <code>InplaceEmphasis</code>)</li></ul><p><strong>Common keyword arguments</strong></p><p>These keyword arguments are common to most Frank-Wolfe variants.</p><div class="admonition is-warning" id="Warning-8d349c160860f6b8"><header class="admonition-header">Warning<a class="admonition-anchor" href="#Warning-8d349c160860f6b8" title="Permalink"></a></header><div class="admonition-body"><p>The current variant may have additional keyword arguments, documented elsewhere, or it may only use a subset of the ones listed below. The default values of these arguments may also vary between variants, and thus are not part of the public API.</p></div></div><ul><li><code>line_search::LineSearchMethod</code>: an object specifying the line search and its parameters (see <a href="../4_linesearch/#FrankWolfe.LineSearchMethod"><code>LineSearchMethod</code></a>)</li><li><code>momentum::Union{Real,Nothing}=nothing</code>: constant momentum to apply to the gradient</li><li><code>epsilon::Real</code>: absolute dual gap threshold at which the algorithm is interrupted</li><li><code>max_iteration::Integer</code>: maximum number of iterations after which the algorithm is interrupted</li><li><code>print_iter::Integer</code>: interval between two consecutive log prints, expressed in number of iterations</li><li><code>trajectory::Bool=false</code>: whether to record the trajectory of algorithm states (through callbacks)</li><li><code>verbose::Bool</code>: whether to print periodic logs (through callbacks)</li><li><code>memory_mode::MemoryEmphasis</code>: an object dictating whether the algorithm operates in-place or out-of-place (see <a href="@ref"><code>MemoryEmphasis</code></a>)</li><li><code>gradient=nothing</code>: pre-allocated container for the gradient</li><li><code>callback=nothing</code>: function called on a <a href="../3_backend/#FrankWolfe.CallbackState"><code>CallbackState</code></a> at each iteration</li><li><code>traj_data=[]</code>: pre-allocated storage for the trajectory of algorithm states</li><li><code>timeout::Real=Inf</code>: maximum time after which the algorithm is interrupted (in nanoseconds)</li><li><code>linesearch_workspace=nothing</code>: pre-allocated workspace for the line search </li><li><code>dual_gap_compute_frequency::Integer=1</code>: frequency of dual gap computation, </li></ul><p><strong>Return</strong></p><p>Returns a tuple <code>(x, v, primal, dual_gap, traj_data, active_set)</code> with:</p><ul><li><code>x</code>: the final iterate</li><li><code>v</code>: the last vertex from the linear minimization oracle</li><li><code>primal</code>: the final primal value <code>f(x)</code></li><li><code>dual_gap</code>: the final Frank-Wolfe gap</li><li><code>traj_data</code>: a vector of trajectory information, each element being the output of <a href="@ref"><code>callback_state</code></a>.</li><li><code>active_set</code>: the computed active set of vertices, of which the solution is a convex combination</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/blended_cg.jl#L2-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.build_reduced_problem-Tuple{AbstractVector{var&quot;#s449&quot;} where var&quot;#s449&quot;&lt;:FrankWolfe.ScaledHotVector, Any, Any, Any, Any}" href="#FrankWolfe.build_reduced_problem-Tuple{AbstractVector{var&quot;#s449&quot;} where var&quot;#s449&quot;&lt;:FrankWolfe.ScaledHotVector, Any, Any, Any, Any}"><code>FrankWolfe.build_reduced_problem</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">build_reduced_problem(atoms::AbstractVector{&lt;:AbstractVector}, hessian, weights, gradient, tolerance)</code></pre><p>Given an active set formed by vectors , a (constant) Hessian and a gradient constructs a quadratic problem over the unit probability simplex that is equivalent to minimizing the original function over the convex hull of the active set. If λ are the barycentric coordinates of dimension equal to the cardinality of the active set, the objective function is:</p><pre><code class="nohighlight hljs">f(λ) = reduced_linear^T λ + 0.5 * λ^T reduced_hessian λ</code></pre><p>In the case where we find that the current iterate has a strong-Wolfe gap over the convex hull of the active set that is below the tolerance we return nothing (as there is nothing to do).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/blended_cg.jl#L586-L603">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.lp_separation_oracle-Tuple{FrankWolfe.LinearMinimizationOracle, FrankWolfe.AbstractActiveSet, Any, Any, Any}" href="#FrankWolfe.lp_separation_oracle-Tuple{FrankWolfe.LinearMinimizationOracle, FrankWolfe.AbstractActiveSet, Any, Any, Any}"><code>FrankWolfe.lp_separation_oracle</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Returns either a tuple <code>(y, val)</code> with <code>y</code> an atom from the active set satisfying the progress criterion and <code>val</code> the corresponding gap <code>dot(y, direction)</code> or the same tuple with <code>y</code> from the LMO.</p><p><code>inplace_loop</code> controls whether the iterate type allows in-place writes. <code>kwargs</code> are passed on to the LMO oracle.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/blended_cg.jl#L1110-L1117">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.minimize_over_convex_hull!-Union{Tuple{R}, Tuple{AT}, Tuple{Any, Any, Any, FrankWolfe.AbstractActiveSet{AT, R, IT} where IT, Any, Any, Any, Any}} where {AT, R}" href="#FrankWolfe.minimize_over_convex_hull!-Union{Tuple{R}, Tuple{AT}, Tuple{Any, Any, Any, FrankWolfe.AbstractActiveSet{AT, R, IT} where IT, Any, Any, Any, Any}} where {AT, R}"><code>FrankWolfe.minimize_over_convex_hull!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">minimize_over_convex_hull!</code></pre><p>Given a function f with gradient grad! and an active set active_set this function will minimize the function over the convex hull of the active set until the strong-wolfe gap over the active set is below tolerance.</p><p>It will either directly minimize over the convex hull using simplex gradient descent, or it will transform the problem to barycentric coordinates and minimize over the unit probability simplex using gradient descent or Nesterov&#39;s accelerated gradient descent.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/blended_cg.jl#L437-L450">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.projection_simplex_sort-Tuple{Any}" href="#FrankWolfe.projection_simplex_sort-Tuple{Any}"><code>FrankWolfe.projection_simplex_sort</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">projection_simplex_sort(x; s=1.0)</code></pre><p>Perform a projection onto the probability simplex of radius <code>s</code> using a sorting algorithm.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/blended_cg.jl#L866-L871">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.simplex_gradient_descent_over_convex_hull-Union{Tuple{R}, Tuple{AT}, Tuple{Any, Any, Any, FrankWolfe.AbstractActiveSet{AT, R, IT} where IT, Any, Any, Any, Any}, Tuple{Any, Any, Any, FrankWolfe.AbstractActiveSet{AT, R, IT} where IT, Any, Any, Any, Any, FrankWolfe.MemoryEmphasis}} where {AT, R}" href="#FrankWolfe.simplex_gradient_descent_over_convex_hull-Union{Tuple{R}, Tuple{AT}, Tuple{Any, Any, Any, FrankWolfe.AbstractActiveSet{AT, R, IT} where IT, Any, Any, Any, Any}, Tuple{Any, Any, Any, FrankWolfe.AbstractActiveSet{AT, R, IT} where IT, Any, Any, Any, Any, FrankWolfe.MemoryEmphasis}} where {AT, R}"><code>FrankWolfe.simplex_gradient_descent_over_convex_hull</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">simplex_gradient_descent_over_convex_hull(f, grad!, gradient, active_set, tolerance, t, time_start, non_simplex_iter)</code></pre><p>Minimizes an objective function over the convex hull of the active set until the Strong-Wolfe gap is below tolerance using simplex gradient descent.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/blended_cg.jl#L910-L916">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.simplex_gradient_descent_over_probability_simplex-Tuple{Any, Any, Any, Any, Any, Any, Any, FrankWolfe.AbstractActiveSet}" href="#FrankWolfe.simplex_gradient_descent_over_probability_simplex-Tuple{Any, Any, Any, Any, Any, Any, Any, FrankWolfe.AbstractActiveSet}"><code>FrankWolfe.simplex_gradient_descent_over_probability_simplex</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">simplex_gradient_descent_over_probability_simplex</code></pre><p>Minimizes an objective function over the unit probability simplex until the Strong-Wolfe gap is below tolerance using gradient descent.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/blended_cg.jl#L794-L799">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.strong_frankwolfe_gap-Tuple{Any}" href="#FrankWolfe.strong_frankwolfe_gap-Tuple{Any}"><code>FrankWolfe.strong_frankwolfe_gap</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Checks the strong Frank-Wolfe gap for the reduced problem.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/blended_cg.jl#L683-L685">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.strong_frankwolfe_gap_probability_simplex-Tuple{Any, Any}" href="#FrankWolfe.strong_frankwolfe_gap_probability_simplex-Tuple{Any, Any}"><code>FrankWolfe.strong_frankwolfe_gap_probability_simplex</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">strong_frankwolfe_gap_probability_simplex</code></pre><p>Compute the Strong-Wolfe gap over the unit probability simplex given a gradient.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/blended_cg.jl#L886-L891">source</a></section></article><h3 id="Blended-Pairwise-Conditional-Gradient"><a class="docs-heading-anchor" href="#Blended-Pairwise-Conditional-Gradient">Blended Pairwise Conditional Gradient</a><a id="Blended-Pairwise-Conditional-Gradient-1"></a><a class="docs-heading-anchor-permalink" href="#Blended-Pairwise-Conditional-Gradient" title="Permalink"></a></h3><h3 id="Corrective-Frank-Wolfe"><a class="docs-heading-anchor" href="#Corrective-Frank-Wolfe">Corrective Frank-Wolfe</a><a id="Corrective-Frank-Wolfe-1"></a><a class="docs-heading-anchor-permalink" href="#Corrective-Frank-Wolfe" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.corrective_frank_wolfe-Union{Tuple{R}, Tuple{AT}, Tuple{Any, Any, Any, FrankWolfe.CorrectiveStep, FrankWolfe.AbstractActiveSet{AT, R, IT} where IT}} where {AT, R}" href="#FrankWolfe.corrective_frank_wolfe-Union{Tuple{R}, Tuple{AT}, Tuple{Any, Any, Any, FrankWolfe.CorrectiveStep, FrankWolfe.AbstractActiveSet{AT, R, IT} where IT}} where {AT, R}"><code>FrankWolfe.corrective_frank_wolfe</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">corrective_frank_wolfe(f, grad!, lmo, corrective_step, active_set::AS; kwargs...)</code></pre><p>A corrective Frank-Wolfe variant with corrective step defined by <code>corrective_step</code>.</p><p>A corrective FW algorithm alternates between a standard FW step at which a vertex is added to the active set and a corrective step at which an update is performed in the convex hull of current vertices. Examples of corrective FW algorithms include blended (pairwise) conditional gradients, away-step Frank-Wolfe, and fully-corrective Frank-Wolfe.</p><p><strong>Common keyword arguments</strong></p><p>These keyword arguments are common to most Frank-Wolfe variants.</p><div class="admonition is-warning" id="Warning-8d349c160860f6b8"><header class="admonition-header">Warning<a class="admonition-anchor" href="#Warning-8d349c160860f6b8" title="Permalink"></a></header><div class="admonition-body"><p>The current variant may have additional keyword arguments, documented elsewhere, or it may only use a subset of the ones listed below. The default values of these arguments may also vary between variants, and thus are not part of the public API.</p></div></div><ul><li><code>line_search::LineSearchMethod</code>: an object specifying the line search and its parameters (see <a href="../4_linesearch/#FrankWolfe.LineSearchMethod"><code>LineSearchMethod</code></a>)</li><li><code>momentum::Union{Real,Nothing}=nothing</code>: constant momentum to apply to the gradient</li><li><code>epsilon::Real</code>: absolute dual gap threshold at which the algorithm is interrupted</li><li><code>max_iteration::Integer</code>: maximum number of iterations after which the algorithm is interrupted</li><li><code>print_iter::Integer</code>: interval between two consecutive log prints, expressed in number of iterations</li><li><code>trajectory::Bool=false</code>: whether to record the trajectory of algorithm states (through callbacks)</li><li><code>verbose::Bool</code>: whether to print periodic logs (through callbacks)</li><li><code>memory_mode::MemoryEmphasis</code>: an object dictating whether the algorithm operates in-place or out-of-place (see <a href="@ref"><code>MemoryEmphasis</code></a>)</li><li><code>gradient=nothing</code>: pre-allocated container for the gradient</li><li><code>callback=nothing</code>: function called on a <a href="../3_backend/#FrankWolfe.CallbackState"><code>CallbackState</code></a> at each iteration</li><li><code>traj_data=[]</code>: pre-allocated storage for the trajectory of algorithm states</li><li><code>timeout::Real=Inf</code>: maximum time after which the algorithm is interrupted (in nanoseconds)</li><li><code>linesearch_workspace=nothing</code>: pre-allocated workspace for the line search </li><li><code>dual_gap_compute_frequency::Integer=1</code>: frequency of dual gap computation, </li></ul><p><strong>Return</strong></p><p>Returns a tuple <code>(x, v, primal, dual_gap, traj_data, active_set)</code> with:</p><ul><li><code>x</code>: the final iterate</li><li><code>v</code>: the last vertex from the linear minimization oracle</li><li><code>primal</code>: the final primal value <code>f(x)</code></li><li><code>dual_gap</code>: the final Frank-Wolfe gap</li><li><code>traj_data</code>: a vector of trajectory information, each element being the output of <a href="@ref"><code>callback_state</code></a>.</li><li><code>active_set</code>: the computed active set of vertices, of which the solution is a convex combination</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/corrective_frankwolfe.jl#L2-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.AwayStep" href="#FrankWolfe.AwayStep"><code>FrankWolfe.AwayStep</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">(Lazified) away-step for corrective Frank-Wolfe</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/corrective_step_interface.jl#L20-L22">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.HybridPairAwayStep" href="#FrankWolfe.HybridPairAwayStep"><code>FrankWolfe.HybridPairAwayStep</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Compares a pairwise and away step and chooses the one with most progress. The line search is computed for both steps. If one step incurs a drop, it is favored, otherwise the one decreasing the primal value the most is favored.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/corrective_step_interface.jl#L362-L366">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.PairwiseStep" href="#FrankWolfe.PairwiseStep"><code>FrankWolfe.PairwiseStep</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Computes a classic pairwise step, i.e., <code>d = v^FW - v^away</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/corrective_step_interface.jl#L627-L629">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.prepare_corrective_step" href="#FrankWolfe.prepare_corrective_step"><code>FrankWolfe.prepare_corrective_step</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">prepare_corrective_step(corrective_step::CS, f, grad!, gradient, active_set, t, lmo, primal, phi, tot_time) -&gt; (should_compute_vertex, use_corrective)</code></pre><p><code>should_compute_vertex</code> is a boolean flag deciding whether a new vertex should be computed. <code>use_corrective</code> is a function that takes the vertex (the vertex is a valid new vertex only if should<em>compute</em>vertex was true)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/corrective_step_interface.jl#L12-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.run_corrective_step" href="#FrankWolfe.run_corrective_step"><code>FrankWolfe.run_corrective_step</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">run_corrective_step(corrective_step, f, grad!, gradient, x, active_set, t, lmo, line_search, linesearch_workspace, primal, phi, tot_time, callback, renorm_interval) -&gt; (x, phi, primal)</code></pre><p>Corrective step method specific to the <code>CS</code> corrective<em>step type. The corrective step can perform whatever update over the current active set, the function should return the new iterate  a FW step should be run next with the boolean `should</em>fw_step<code>and compute a new dual gap estimate</code>phi`.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/corrective_step_interface.jl#L4-L9">source</a></section></article><h2 id="Alternating-Methods"><a class="docs-heading-anchor" href="#Alternating-Methods">Alternating Methods</a><a id="Alternating-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Alternating-Methods" title="Permalink"></a></h2><p>Problems over intersections of convex sets, i.e.</p><p class="math-container">\[\min_{x \in \bigcap_{i=1}^n P_i} f(x),\]</p><p>pose a challenge as one has to combine the information of two or more LMOs.</p><p><a href="#FrankWolfe.alternating_linear_minimization-Union{Tuple{LS}, Tuple{N}, Tuple{Any, Any, Any, Tuple{Vararg{FrankWolfe.LinearMinimizationOracle, N}}, Tuple{Vararg{Any, N}}}} where {N, LS&lt;:Union{Tuple{Vararg{FrankWolfe.LineSearchMethod, N}}, FrankWolfe.LineSearchMethod}}"><code>FrankWolfe.alternating_linear_minimization</code></a> converts the problem into a series of subproblems over single sets. To find a point within the intersection, one minimizes both the distance to the iterates of the other subproblems and the original objective function.</p><p><a href="#FrankWolfe.alternating_projections-Union{Tuple{N}, Tuple{Tuple{Vararg{FrankWolfe.LinearMinimizationOracle, N}}, Any}} where N"><code>FrankWolfe.alternating_projections</code></a> solves feasibility problems over intersections of feasible regions.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.alternating_linear_minimization-Union{Tuple{LS}, Tuple{N}, Tuple{Any, Any, Any, Tuple{Vararg{FrankWolfe.LinearMinimizationOracle, N}}, Tuple{Vararg{Any, N}}}} where {N, LS&lt;:Union{Tuple{Vararg{FrankWolfe.LineSearchMethod, N}}, FrankWolfe.LineSearchMethod}}" href="#FrankWolfe.alternating_linear_minimization-Union{Tuple{LS}, Tuple{N}, Tuple{Any, Any, Any, Tuple{Vararg{FrankWolfe.LinearMinimizationOracle, N}}, Tuple{Vararg{Any, N}}}} where {N, LS&lt;:Union{Tuple{Vararg{FrankWolfe.LineSearchMethod, N}}, FrankWolfe.LineSearchMethod}}"><code>FrankWolfe.alternating_linear_minimization</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">alternating_linear_minimization(bc_algo::BlockCoordinateMethod, f, grad!, lmos::NTuple{N,LinearMinimizationOracle}, x0; ...) where {N}</code></pre><p>Alternating Linear Minimization minimizes the objective <code>f</code> over the intersections of the feasible domains specified by <code>lmos</code>. The tuple <code>x0</code> defines the initial points for each domain. Returns a tuple <code>(x, v, primal, dual_gap, dist2, traj_data)</code> with:</p><ul><li><code>x</code> cartesian product of final iterates</li><li><code>v</code> cartesian product of last vertices of the LMOs</li><li><code>primal</code> primal value <code>f(x)</code></li><li><code>dual_gap</code> final Frank-Wolfe gap</li><li><code>dist2</code> is 1/2 of the sum of squared, pairwise distances between iterates</li><li><code>traj_data</code> vector of trajectory information.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/alternating_methods.jl#L33-L45">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="FrankWolfe.alternating_projections-Union{Tuple{N}, Tuple{Tuple{Vararg{FrankWolfe.LinearMinimizationOracle, N}}, Any}} where N" href="#FrankWolfe.alternating_projections-Union{Tuple{N}, Tuple{Tuple{Vararg{FrankWolfe.LinearMinimizationOracle, N}}, Any}} where N"><code>FrankWolfe.alternating_projections</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">alternating_projections(lmos::NTuple{N,LinearMinimizationOracle}, x0; ...) where {N}</code></pre><p>Computes a point in the intersection of feasible domains specified by <code>lmos</code>. Returns a tuple <code>(x, v, dual_gap, dist2, traj_data)</code> with:</p><ul><li><code>x</code> cartesian product of final iterates</li><li><code>v</code> cartesian product of last vertices of the LMOs</li><li><code>dual_gap</code> final Frank-Wolfe gap</li><li><code>dist2</code> is 1/2 * sum of squared, pairwise distances between iterates</li><li><code>traj_data</code> vector of trajectory information.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/f410fb92101eba05238396b61d75b67c803df35f/src/alternating_methods.jl#L217-L227">source</a></section></article><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../0_reference/">« API Reference</a><a class="docs-footer-nextpage" href="../2_lmo/">Linear Minimization Oracles »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Wednesday 16 July 2025 08:15">Wednesday 16 July 2025</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Algorithms · FrankWolfe.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">FrankWolfe.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../basics/">How does it work?</a></li><li><a class="tocitem" href="../../advanced/">Advanced features</a></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../examples/docs_0_fw_visualized/">Visualization of Frank-Wolfe running on a 2-dimensional polytope</a></li><li><a class="tocitem" href="../../examples/docs_1_mathopt_lmo/">Comparison with MathOptInterface on a Probability Simplex</a></li><li><a class="tocitem" href="../../examples/docs_2_polynomial_regression/">Polynomial Regression</a></li><li><a class="tocitem" href="../../examples/docs_3_matrix_completion/">Matrix Completion</a></li><li><a class="tocitem" href="../../examples/docs_4_rational_opt/">Exact Optimization with Rational Arithmetic</a></li><li><a class="tocitem" href="../../examples/docs_5_blended_cg/">Blended Conditional Gradients</a></li><li><a class="tocitem" href="../../examples/docs_6_spectrahedron/">Spectrahedron</a></li><li><a class="tocitem" href="../../examples/docs_7_shifted_norm_polytopes/">FrankWolfe for scaled, shifted <span>$\ell^1$</span> and <span>$\ell^{\infty}$</span> norm balls</a></li><li><a class="tocitem" href="../../examples/docs_8_callback_and_tracking/">Tracking, counters and custom callbacks for Frank Wolfe</a></li><li><a class="tocitem" href="../../examples/docs_9_extra_vertex_storage/">Extra-lazification</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox" checked/><label class="tocitem" for="menuitem-5"><span class="docs-label">API reference</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../1_lmo/">Linear Minimization Oracles</a></li><li class="is-active"><a class="tocitem" href>Algorithms</a><ul class="internal"><li><a class="tocitem" href="#Standard"><span>Standard</span></a></li><li><a class="tocitem" href="#Away-step"><span>Away-step</span></a></li><li><a class="tocitem" href="#Blended-CG"><span>Blended CG</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li><li><a class="tocitem" href="../3_backend/">Utilities and data structures</a></li><li><a class="tocitem" href="../4_linesearch/">Line search and step size settings</a></li></ul></li><li><a class="tocitem" href="../../contributing/">Contributing</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API reference</a></li><li class="is-active"><a href>Algorithms</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Algorithms</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/master/docs/src/reference/2_algorithms.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Algorithms"><a class="docs-heading-anchor" href="#Algorithms">Algorithms</a><a id="Algorithms-1"></a><a class="docs-heading-anchor-permalink" href="#Algorithms" title="Permalink"></a></h1><h2 id="Standard"><a class="docs-heading-anchor" href="#Standard">Standard</a><a id="Standard-1"></a><a class="docs-heading-anchor-permalink" href="#Standard" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="FrankWolfe.frank_wolfe-NTuple{4, Any}" href="#FrankWolfe.frank_wolfe-NTuple{4, Any}"><code>FrankWolfe.frank_wolfe</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">frank_wolfe(f, grad!, lmo, x0; ...)</code></pre><p>Simplest form of the Frank-Wolfe algorithm. Returns a tuple <code>(x, v, primal, dual_gap, traj_data)</code> with:</p><ul><li><code>x</code> final iterate</li><li><code>v</code> last vertex from the LMO</li><li><code>primal</code> primal value <code>f(x)</code></li><li><code>dual_gap</code> final Frank-Wolfe gap</li><li><code>traj_data</code> vector of trajectory information.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/647364039c735d5499c7efa40d2ec02562644aed/src/fw_algorithms.jl#L2-L12">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="FrankWolfe.lazified_conditional_gradient-NTuple{4, Any}" href="#FrankWolfe.lazified_conditional_gradient-NTuple{4, Any}"><code>FrankWolfe.lazified_conditional_gradient</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">lazified_conditional_gradient</code></pre><p>Similar to <a href="../#FrankWolfe.frank_wolfe"><code>frank_wolfe</code></a> but lazyfying the LMO: each call is stored in a cache, which is looked up first for a good-enough direction. The cache used is a <a href="../#FrankWolfe.MultiCacheLMO"><code>FrankWolfe.MultiCacheLMO</code></a> or a <a href="../#FrankWolfe.VectorCacheLMO"><code>FrankWolfe.VectorCacheLMO</code></a> depending on whether the provided <code>cache_size</code> option is finite.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/647364039c735d5499c7efa40d2ec02562644aed/src/fw_algorithms.jl#L239-L246">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="FrankWolfe.stochastic_frank_wolfe-Tuple{FrankWolfe.StochasticObjective, Any, Any}" href="#FrankWolfe.stochastic_frank_wolfe-Tuple{FrankWolfe.StochasticObjective, Any, Any}"><code>FrankWolfe.stochastic_frank_wolfe</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">stochastic_frank_wolfe(f::StochasticObjective, lmo, x0; ...)</code></pre><p>Stochastic version of Frank-Wolfe, evaluates the objective and gradient stochastically, implemented through the <a href="../#FrankWolfe.StochasticObjective"><code>FrankWolfe.StochasticObjective</code></a> interface.</p><p>Keyword arguments include <code>batch_size</code> to pass a fixed <code>batch_size</code> or a <code>batch_iterator</code> implementing <code>batch_size = FrankWolfe.batchsize_iterate(batch_iterator)</code> for algorithms like Variance-reduced and projection-free stochastic optimization, E Hazan, H Luo, 2016.</p><p>Similarly, a constant <code>momentum</code> can be passed or replaced by a <code>momentum_iterator</code> implementing <code>momentum = FrankWolfe.momentum_iterate(momentum_iterator)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/647364039c735d5499c7efa40d2ec02562644aed/src/fw_algorithms.jl#L467-L480">source</a></section></article><h2 id="Away-step"><a class="docs-heading-anchor" href="#Away-step">Away-step</a><a id="Away-step-1"></a><a class="docs-heading-anchor-permalink" href="#Away-step" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="FrankWolfe.away_frank_wolfe-NTuple{4, Any}" href="#FrankWolfe.away_frank_wolfe-NTuple{4, Any}"><code>FrankWolfe.away_frank_wolfe</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">away_frank_wolfe</code></pre><p>Frank-Wolfe with away steps. The algorithm maintains the current iterate as a convex combination of vertices in the <a href="../#FrankWolfe.ActiveSet"><code>FrankWolfe.ActiveSet</code></a> data structure. See the <a href="https://arxiv.org/abs/2104.06675">paper</a> for illustrations of away steps.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/647364039c735d5499c7efa40d2ec02562644aed/src/afw.jl#L2-L9">source</a></section></article><h2 id="Blended-CG"><a class="docs-heading-anchor" href="#Blended-CG">Blended CG</a><a id="Blended-CG-1"></a><a class="docs-heading-anchor-permalink" href="#Blended-CG" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="FrankWolfe.accelerated_simplex_gradient_descent_over_probability_simplex-Tuple{Any, Any, Any, Any, Any, Any, FrankWolfe.ActiveSet}" href="#FrankWolfe.accelerated_simplex_gradient_descent_over_probability_simplex-Tuple{Any, Any, Any, Any, Any, Any, FrankWolfe.ActiveSet}"><code>FrankWolfe.accelerated_simplex_gradient_descent_over_probability_simplex</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">accelerated_simplex_gradient_descent_over_probability_simplex</code></pre><p>Minimizes an objective function over the unit probability simplex until the Strong-Wolfe gap is below tolerance using Nesterov&#39;s accelerated gradient descent.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/647364039c735d5499c7efa40d2ec02562644aed/src/blended_cg.jl#L555-L561">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="FrankWolfe.blended_conditional_gradient-NTuple{4, Any}" href="#FrankWolfe.blended_conditional_gradient-NTuple{4, Any}"><code>FrankWolfe.blended_conditional_gradient</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">blended_conditional_gradient(f, grad!, lmo, x0)</code></pre><p>Entry point for the Blended Conditional Gradient algorithm. See Braun, Gábor, et al. &quot;Blended conditonal gradients&quot; ICML 2019. The method works on an active set like <a href="../#FrankWolfe.away_frank_wolfe"><code>FrankWolfe.away_frank_wolfe</code></a>, performing gradient descent over the convex hull of active vertices, removing vertices when their weight drops to 0 and adding new vertices by calling the linear oracle in a lazy fashion.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/647364039c735d5499c7efa40d2ec02562644aed/src/blended_cg.jl#L2-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="FrankWolfe.build_reduced_problem-Tuple{AbstractVector{var&quot;#s69&quot;} where var&quot;#s69&quot;&lt;:FrankWolfe.ScaledHotVector, Any, Any, Any, Any}" href="#FrankWolfe.build_reduced_problem-Tuple{AbstractVector{var&quot;#s69&quot;} where var&quot;#s69&quot;&lt;:FrankWolfe.ScaledHotVector, Any, Any, Any, Any}"><code>FrankWolfe.build_reduced_problem</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">build_reduced_problem(atoms::AbstractVector{&lt;:AbstractVector}, hessian, weights, gradient, tolerance)</code></pre><p>Given an active set formed by vectors , a (constant) Hessian and a gradient constructs a quadratic problem over the unit probability simplex that is equivalent to minimizing the original function over the convex hull of the active set. If λ are the barycentric coordinates of dimension equal to the cardinality of the active set, the objective function is:     f(λ) = reduced<em>linear^T λ + 0.5 * λ^T reduced</em>hessian λ</p><p>In the case where we find that the current iterate has a strong-Wolfe gap over the convex hull of the active set that is below the tolerance we return nothing (as there is nothing to do).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/647364039c735d5499c7efa40d2ec02562644aed/src/blended_cg.jl#L441-L457">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="FrankWolfe.lp_separation_oracle-Tuple{FrankWolfe.LinearMinimizationOracle, FrankWolfe.ActiveSet, Any, Any, Any}" href="#FrankWolfe.lp_separation_oracle-Tuple{FrankWolfe.LinearMinimizationOracle, FrankWolfe.ActiveSet, Any, Any, Any}"><code>FrankWolfe.lp_separation_oracle</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Returns either a tuple <code>(y, val)</code> with <code>y</code> an atom from the active set satisfying the progress criterion and <code>val</code> the corresponding gap <code>dot(y, direction)</code> or the same tuple with <code>y</code> from the LMO.</p><p><code>inplace_loop</code> controls whether the iterate type allows in-place writes. <code>kwargs</code> are passed on to the LMO oracle.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/647364039c735d5499c7efa40d2ec02562644aed/src/blended_cg.jl#L952-L959">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="FrankWolfe.minimize_over_convex_hull!-Tuple{Any, Any, Any, FrankWolfe.ActiveSet, Any, Any, Any, Any}" href="#FrankWolfe.minimize_over_convex_hull!-Tuple{Any, Any, Any, FrankWolfe.ActiveSet, Any, Any, Any, Any}"><code>FrankWolfe.minimize_over_convex_hull!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">minimize_over_convex_hull!</code></pre><p>Given a function f with gradient grad! and an active set active_set this function will minimize the function over the convex hull of the active set until the strong-wolfe gap over the active set is below tolerance.</p><p>It will either directly minimize over the convex hull using simplex gradient descent, or it will transform the problem to barycentric coordinates and minimize over the unit probability simplex using gradient descent or Nesterov&#39;s accelerated gradient descent.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/647364039c735d5499c7efa40d2ec02562644aed/src/blended_cg.jl#L306-L319">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="FrankWolfe.projection_simplex_sort-Tuple{Any}" href="#FrankWolfe.projection_simplex_sort-Tuple{Any}"><code>FrankWolfe.projection_simplex_sort</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">projection_simplex_sort(x; s=1.0)</code></pre><p>Perform a projection onto the probability simplex of radius <code>s</code> using a sorting algorithm.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/647364039c735d5499c7efa40d2ec02562644aed/src/blended_cg.jl#L721-L726">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="FrankWolfe.simplex_gradient_descent_over_convex_hull" href="#FrankWolfe.simplex_gradient_descent_over_convex_hull"><code>FrankWolfe.simplex_gradient_descent_over_convex_hull</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">simplex_gradient_descent_over_convex_hull(f, grad!, gradient, active_set, tolerance, t, time_start, non_simplex_iter)</code></pre><p>Minimizes an objective function over the convex hull of the active set until the Strong-Wolfe gap is below tolerance using simplex gradient descent.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/647364039c735d5499c7efa40d2ec02562644aed/src/blended_cg.jl#L765-L771">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="FrankWolfe.simplex_gradient_descent_over_probability_simplex-Tuple{Any, Any, Any, Any, Any, Any, Any, FrankWolfe.ActiveSet}" href="#FrankWolfe.simplex_gradient_descent_over_probability_simplex-Tuple{Any, Any, Any, Any, Any, Any, Any, FrankWolfe.ActiveSet}"><code>FrankWolfe.simplex_gradient_descent_over_probability_simplex</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">simplex_gradient_descent_over_probability_simplex</code></pre><p>Minimizes an objective function over the unit probability simplex until the Strong-Wolfe gap is below tolerance using gradient descent.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/647364039c735d5499c7efa40d2ec02562644aed/src/blended_cg.jl#L649-L654">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="FrankWolfe.strong_frankwolfe_gap-Tuple{Any}" href="#FrankWolfe.strong_frankwolfe_gap-Tuple{Any}"><code>FrankWolfe.strong_frankwolfe_gap</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Checks the strong Frank-Wolfe gap for the reduced problem.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/647364039c735d5499c7efa40d2ec02562644aed/src/blended_cg.jl#L537-L539">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="FrankWolfe.strong_frankwolfe_gap_probability_simplex-Tuple{Any, Any}" href="#FrankWolfe.strong_frankwolfe_gap_probability_simplex-Tuple{Any, Any}"><code>FrankWolfe.strong_frankwolfe_gap_probability_simplex</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">strong_frankwolfe_gap_probability_simplex</code></pre><p>Compute the Strong-Wolfe gap over the unit probability simplex given a gradient.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/647364039c735d5499c7efa40d2ec02562644aed/src/blended_cg.jl#L741-L746">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="FrankWolfe.blended_pairwise_conditional_gradient-NTuple{4, Any}" href="#FrankWolfe.blended_pairwise_conditional_gradient-NTuple{4, Any}"><code>FrankWolfe.blended_pairwise_conditional_gradient</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">blended_pairwise_conditional_gradient(f, grad!, lmo, x0; kwargs...)</code></pre><p>Implements the BPCG algorithm from <a href="https://arxiv.org/abs/2110.12650">Tsuji, Tanaka, Pokutta</a>. The method uses an active set of current vertices. Unlike away-step, it transfers weight from an away vertex to another vertex of the active set.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/647364039c735d5499c7efa40d2ec02562644aed/src/pairwise.jl#L2-L8">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="FrankWolfe.blended_pairwise_conditional_gradient-Tuple{Any, Any, Any, FrankWolfe.ActiveSet}" href="#FrankWolfe.blended_pairwise_conditional_gradient-Tuple{Any, Any, Any, FrankWolfe.ActiveSet}"><code>FrankWolfe.blended_pairwise_conditional_gradient</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">blended_pairwise_conditional_gradient(f, grad!, lmo, active_set::ActiveSet; kwargs...)</code></pre><p>Warm-starts BPCG with a pre-defined <code>active_set</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/647364039c735d5499c7efa40d2ec02562644aed/src/pairwise.jl#L62-L66">source</a></section></article><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#FrankWolfe.accelerated_simplex_gradient_descent_over_probability_simplex-Tuple{Any, Any, Any, Any, Any, Any, FrankWolfe.ActiveSet}"><code>FrankWolfe.accelerated_simplex_gradient_descent_over_probability_simplex</code></a></li><li><a href="#FrankWolfe.away_frank_wolfe-NTuple{4, Any}"><code>FrankWolfe.away_frank_wolfe</code></a></li><li><a href="#FrankWolfe.blended_conditional_gradient-NTuple{4, Any}"><code>FrankWolfe.blended_conditional_gradient</code></a></li><li><a href="#FrankWolfe.blended_pairwise_conditional_gradient-NTuple{4, Any}"><code>FrankWolfe.blended_pairwise_conditional_gradient</code></a></li><li><a href="#FrankWolfe.blended_pairwise_conditional_gradient-Tuple{Any, Any, Any, FrankWolfe.ActiveSet}"><code>FrankWolfe.blended_pairwise_conditional_gradient</code></a></li><li><a href="#FrankWolfe.build_reduced_problem-Tuple{AbstractVector{var&quot;#s69&quot;} where var&quot;#s69&quot;&lt;:FrankWolfe.ScaledHotVector, Any, Any, Any, Any}"><code>FrankWolfe.build_reduced_problem</code></a></li><li><a href="#FrankWolfe.frank_wolfe-NTuple{4, Any}"><code>FrankWolfe.frank_wolfe</code></a></li><li><a href="#FrankWolfe.lazified_conditional_gradient-NTuple{4, Any}"><code>FrankWolfe.lazified_conditional_gradient</code></a></li><li><a href="#FrankWolfe.lp_separation_oracle-Tuple{FrankWolfe.LinearMinimizationOracle, FrankWolfe.ActiveSet, Any, Any, Any}"><code>FrankWolfe.lp_separation_oracle</code></a></li><li><a href="#FrankWolfe.minimize_over_convex_hull!-Tuple{Any, Any, Any, FrankWolfe.ActiveSet, Any, Any, Any, Any}"><code>FrankWolfe.minimize_over_convex_hull!</code></a></li><li><a href="#FrankWolfe.projection_simplex_sort-Tuple{Any}"><code>FrankWolfe.projection_simplex_sort</code></a></li><li><a href="#FrankWolfe.simplex_gradient_descent_over_convex_hull"><code>FrankWolfe.simplex_gradient_descent_over_convex_hull</code></a></li><li><a href="#FrankWolfe.simplex_gradient_descent_over_probability_simplex-Tuple{Any, Any, Any, Any, Any, Any, Any, FrankWolfe.ActiveSet}"><code>FrankWolfe.simplex_gradient_descent_over_probability_simplex</code></a></li><li><a href="#FrankWolfe.stochastic_frank_wolfe-Tuple{FrankWolfe.StochasticObjective, Any, Any}"><code>FrankWolfe.stochastic_frank_wolfe</code></a></li><li><a href="#FrankWolfe.strong_frankwolfe_gap-Tuple{Any}"><code>FrankWolfe.strong_frankwolfe_gap</code></a></li><li><a href="#FrankWolfe.strong_frankwolfe_gap_probability_simplex-Tuple{Any, Any}"><code>FrankWolfe.strong_frankwolfe_gap_probability_simplex</code></a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../1_lmo/">« Linear Minimization Oracles</a><a class="docs-footer-nextpage" href="../3_backend/">Utilities and data structures »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.20 on <span class="colophon-date" title="Monday 11 July 2022 16:11">Monday 11 July 2022</span>. Using Julia version 1.6.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

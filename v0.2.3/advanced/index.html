<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Advanced features · FrankWolfe.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">FrankWolfe.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../basics/">How does it work?</a></li><li class="is-active"><a class="tocitem" href>Advanced features</a><ul class="internal"><li><a class="tocitem" href="#Multi-precision"><span>Multi-precision</span></a></li><li><a class="tocitem" href="#Step-size-computation"><span>Step size computation</span></a></li><li><a class="tocitem" href="#Callbacks"><span>Callbacks</span></a></li><li><a class="tocitem" href="#Custom-extreme-point-types"><span>Custom extreme point types</span></a></li><li><a class="tocitem" href="#Active-set"><span>Active set</span></a></li><li><a class="tocitem" href="#Extra-lazification-with-a-vertex-storage"><span>Extra-lazification with a vertex storage</span></a></li><li><a class="tocitem" href="#Miscellaneous"><span>Miscellaneous</span></a></li><li><a class="tocitem" href="#Rational-arithmetic"><span>Rational arithmetic</span></a></li><li><a class="tocitem" href="#Large-scale-problems"><span>Large-scale problems</span></a></li><li><a class="tocitem" href="#Iterate-and-atom-expected-interface"><span>Iterate and atom expected interface</span></a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../examples/docs_0_fw_visualized/">Visualization of Frank-Wolfe running on a 2-dimensional polytope</a></li><li><a class="tocitem" href="../examples/docs_1_mathopt_lmo/">Comparison with MathOptInterface on a Probability Simplex</a></li><li><a class="tocitem" href="../examples/docs_2_polynomial_regression/">Polynomial Regression</a></li><li><a class="tocitem" href="../examples/docs_3_matrix_completion/">Matrix Completion</a></li><li><a class="tocitem" href="../examples/docs_4_rational_opt/">Exact Optimization with Rational Arithmetic</a></li><li><a class="tocitem" href="../examples/docs_5_blended_cg/">Blended Conditional Gradients</a></li><li><a class="tocitem" href="../examples/docs_6_spectrahedron/">Spectrahedron</a></li><li><a class="tocitem" href="../examples/docs_7_shifted_norm_polytopes/">FrankWolfe for scaled, shifted <span>$\ell^1$</span> and <span>$\ell^{\infty}$</span> norm balls</a></li><li><a class="tocitem" href="../examples/docs_8_callback_and_tracking/">Tracking, counters and custom callbacks for Frank Wolfe</a></li><li><a class="tocitem" href="../examples/docs_9_extra_vertex_storage/">Extra-lazification</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">API reference</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../reference/1_lmo/">Linear Minimization Oracles</a></li><li><a class="tocitem" href="../reference/2_algorithms/">Algorithms</a></li><li><a class="tocitem" href="../reference/3_backend/">Utilities and data structures</a></li><li><a class="tocitem" href="../reference/4_linesearch/">Line search and step size settings</a></li></ul></li><li><a class="tocitem" href="../contributing/">Contributing</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Advanced features</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Advanced features</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/ZIB-IOL/FrankWolfe.jl/blob/master/docs/src/advanced.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Advanced-features"><a class="docs-heading-anchor" href="#Advanced-features">Advanced features</a><a id="Advanced-features-1"></a><a class="docs-heading-anchor-permalink" href="#Advanced-features" title="Permalink"></a></h1><h2 id="Multi-precision"><a class="docs-heading-anchor" href="#Multi-precision">Multi-precision</a><a id="Multi-precision-1"></a><a class="docs-heading-anchor-permalink" href="#Multi-precision" title="Permalink"></a></h2><p>All algorithms can run in various precisions modes: <code>Float16, Float32, Float64, BigFloat</code> and also for rationals based on various integer types <code>Int32, Int64, BigInt</code> (see e.g., the approximate Carathéodory example)</p><h2 id="Step-size-computation"><a class="docs-heading-anchor" href="#Step-size-computation">Step size computation</a><a id="Step-size-computation-1"></a><a class="docs-heading-anchor-permalink" href="#Step-size-computation" title="Permalink"></a></h2><p>For all Frank-Wolfe algorithms, a step size must be determined to move from the current iterate to the next one. This step size can be determined by exact line search or any other rule represented by a subtype of <a href="../reference/4_linesearch/#FrankWolfe.LineSearchMethod"><code>FrankWolfe.LineSearchMethod</code></a>, which must implement <a href="@ref"><code>FrankWolfe.line_search_wrapper</code></a>.</p><p>Multiple line search and step size determination rules are already  available. See <a href="https://arxiv.org/abs/1806.05123">Pedregosa, Negiar, Askari, Jaggi (2020)</a> for the adaptive step size and <a href="https://openreview.net/forum?id=rq_UD6IiBpX">Carderera, Besançon, Pokutta (2021)</a> for the monotonic step size.</p><h2 id="Callbacks"><a class="docs-heading-anchor" href="#Callbacks">Callbacks</a><a id="Callbacks-1"></a><a class="docs-heading-anchor-permalink" href="#Callbacks" title="Permalink"></a></h2><p>All top-level algorithms can take an optional <code>callback</code> argument, which must be a function taking a <a href="../reference/3_backend/#FrankWolfe.CallbackState"><code>FrankWolfe.CallbackState</code></a> struct and additional arguments:</p><pre><code class="language-julia hljs">callback(state::FrankWolfe.CallbackState, args...)</code></pre><p>The callback can be used to log additional information or store some values of interest in an external array. If a callback is passed, the <code>trajectory</code> keyword is ignored since it is a special case of callback pushing the 5 first elements of the state to an array returned from the algorithm.</p><h2 id="Custom-extreme-point-types"><a class="docs-heading-anchor" href="#Custom-extreme-point-types">Custom extreme point types</a><a id="Custom-extreme-point-types-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-extreme-point-types" title="Permalink"></a></h2><p>For some feasible sets, the extreme points of the feasible set returned by the LMO possess a specific structure that can be represented in an efficient manner both for storage and for common operations like scaling and addition with an iterate. See for example <a href="../reference/#FrankWolfe.ScaledHotVector"><code>FrankWolfe.ScaledHotVector</code></a> and <a href="../reference/#FrankWolfe.RankOneMatrix"><code>FrankWolfe.RankOneMatrix</code></a>.</p><h2 id="Active-set"><a class="docs-heading-anchor" href="#Active-set">Active set</a><a id="Active-set-1"></a><a class="docs-heading-anchor-permalink" href="#Active-set" title="Permalink"></a></h2><p>The active set represents an iterate as a convex combination of atoms (also referred to as extreme points or vertices). It maintains a vector of atoms, the corresponding weights, and the current iterate.</p><p>Note: the weights in the active set are currently defined as <code>Float64</code> in the algorithm. This means that even with vertices using a lower precision, the iterate <code>sum_i(lambda_i * v_i)</code> will be upcast to <code>Float64</code>. One reason for keeping this as-is for now is the higher precision required by the computation of iterates from their barycentric decomposition.</p><h2 id="Extra-lazification-with-a-vertex-storage"><a class="docs-heading-anchor" href="#Extra-lazification-with-a-vertex-storage">Extra-lazification with a vertex storage</a><a id="Extra-lazification-with-a-vertex-storage-1"></a><a class="docs-heading-anchor-permalink" href="#Extra-lazification-with-a-vertex-storage" title="Permalink"></a></h2><p>One can pass the following keyword arguments to some active set-based Frank-Wolfe algorithms:</p><pre><code class="language-julia hljs">add_dropped_vertices=true,
use_extra_vertex_storage=true,
extra_vertex_storage=vertex_storage,</code></pre><p><code>add_dropped_vertices</code> activates feeding discarded vertices to the storage while <code>use_extra_vertex_storage</code> determines whether vertices from the storage are used in the algorithm. See <a href="../examples/docs_9_extra_vertex_storage/#Extra-lazification">Extra-lazification</a> for a complete example.</p><h2 id="Miscellaneous"><a class="docs-heading-anchor" href="#Miscellaneous">Miscellaneous</a><a id="Miscellaneous-1"></a><a class="docs-heading-anchor-permalink" href="#Miscellaneous" title="Permalink"></a></h2><ul><li>Emphasis: All solvers support emphasis (parameter <code>Emphasis</code>) to either exploit vectorized linear algebra or be memory efficient, e.g., for large-scale instances</li><li>Various caching strategies for the lazy implementations. Unbounded cache sizes (can get slow), bounded cache sizes as well as early returns once any sufficient vertex is found in the cache.</li><li>Optionally all algorithms can be endowed with gradient momentum. This might help convergence especially in the stochastic context.</li></ul><p>Coming soon: when the LMO can compute dual prices, then the Frank-Wolfe algorithms will return dual prices for the (approximately) optimal solutions (see <a href="https://arxiv.org/abs/2101.02087">Braun, Pokutta (2021)</a>).</p><h2 id="Rational-arithmetic"><a class="docs-heading-anchor" href="#Rational-arithmetic">Rational arithmetic</a><a id="Rational-arithmetic-1"></a><a class="docs-heading-anchor-permalink" href="#Rational-arithmetic" title="Permalink"></a></h2><p>Example: <code>examples/approximateCaratheodory.jl</code></p><p>We can solve the approximate Carathéodory problem with rational arithmetic to obtain rational approximations; see <a href="https://arxiv.org/abs/1911.04415">Combettes, Pokutta 2019</a> for some background about approximate Carathéodory and Conditioanl Gradients. We consider the simple instance of approximating the <code>0</code> over the probability simplex here:</p><p>&lt;p class=&quot;aligncenter&quot;&gt; &lt;img src=&quot;https://render.githubusercontent.com/render/math?math=\min_{x \in \Delta(n)} \|x\|^2&quot;&gt; &lt;/p&gt;</p><p>with n = 100.</p><pre><code class="nohighlight hljs">Vanilla Frank-Wolfe Algorithm.
EMPHASIS: blas STEPSIZE: rationalshortstep EPSILON: 1.0e-7 max_iteration: 100 TYPE: Rational{BigInt}

───────────────────────────────────────────────────────────────────────────────────
  Type     Iteration         Primal           Dual       Dual Gap           Time
───────────────────────────────────────────────────────────────────────────────────
     I             0   1.000000e+00  -1.000000e+00   2.000000e+00   1.540385e-01
    FW            10   9.090909e-02  -9.090909e-02   1.818182e-01   2.821186e-01
    FW            20   4.761905e-02  -4.761905e-02   9.523810e-02   3.027964e-01
    FW            30   3.225806e-02  -3.225806e-02   6.451613e-02   3.100331e-01
    FW            40   2.439024e-02  -2.439024e-02   4.878049e-02   3.171654e-01
    FW            50   1.960784e-02  -1.960784e-02   3.921569e-02   3.244207e-01
    FW            60   1.639344e-02  -1.639344e-02   3.278689e-02   3.326185e-01
    FW            70   1.408451e-02  -1.408451e-02   2.816901e-02   3.418239e-01
    FW            80   1.234568e-02  -1.234568e-02   2.469136e-02   3.518750e-01
    FW            90   1.098901e-02  -1.098901e-02   2.197802e-02   3.620287e-01
  Last                 1.000000e-02   1.000000e-02   0.000000e+00   4.392171e-01
───────────────────────────────────────────────────────────────────────────────────

  0.600608 seconds (3.83 M allocations: 111.274 MiB, 12.97% gc time)

Output type of solution: Rational{BigInt}</code></pre><p>The solution returned is rational as we can see and in fact the exactly optimal solution:</p><pre><code class="nohighlight hljs">x = Rational{BigInt}[1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100, 1//100]</code></pre><h2 id="Large-scale-problems"><a class="docs-heading-anchor" href="#Large-scale-problems">Large-scale problems</a><a id="Large-scale-problems-1"></a><a class="docs-heading-anchor-permalink" href="#Large-scale-problems" title="Permalink"></a></h2><p>Example: <code>examples/large_scale.jl</code></p><p>The package is built to scale well, for those conditional gradients variants that can scale well. For example, Away-Step Frank-Wolfe and Pairwise Conditional Gradients do in most cases <em>not scale well</em> because they need to maintain active sets and maintaining them can be very expensive. Similarly, line search methods might become prohibitive at large sizes. However if we consider scale-friendly variants, e.g., the vanilla Frank-Wolfe algorithm with the agnostic step size rule or short step rule, then these algorithms can scale well to extreme sizes esentially only limited by the amount of memory available. However even for these methods that tend to scale well, allocation of memory itself can be very slow when you need to allocate gigabytes of memory for a single gradient computation.</p><p>The package is build to support extreme sizes with a special memory efficient emphasis <code>emphasis=FrankWolfe.memory</code>, which minimizes expensive memory allocations and performs as many operations in-place as possible.</p><p>Here is an example of a run with 1e9 variables. Each gradient is around 7.5 GB in size. Here is the output of the run broken down into pieces:</p><pre><code class="nohighlight hljs">Size of single vector (Float64): 7629.39453125 MB
Testing f... 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| Time: 0:00:23
Testing grad... 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| Time: 0:00:23
Testing lmo... 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| Time: 0:00:29
Testing dual gap... 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| Time: 0:00:46
Testing update... (Emphasis: blas) 100%|███████████████████████████████████████████████████████████████████████████████████████████████| Time: 0:01:35
Testing update... (Emphasis: memory) 100%|█████████████████████████████████████████████████████████████████████████████████████████████| Time: 0:00:58
 ──────────────────────────────────────────────────────────────────────────
                                   Time                   Allocations
                           ──────────────────────   ───────────────────────
     Tot / % measured:           278s / 31.4%            969GiB / 30.8%

 Section           ncalls     time   %tot     avg     alloc   %tot      avg
 ──────────────────────────────────────────────────────────────────────────
 update (blas)         10    36.1s  41.3%   3.61s    149GiB  50.0%  14.9GiB
 lmo                   10    18.4s  21.1%   1.84s     0.00B  0.00%    0.00B
 grad                  10    12.8s  14.6%   1.28s   74.5GiB  25.0%  7.45GiB
 f                     10    12.7s  14.5%   1.27s   74.5GiB  25.0%  7.45GiB
 update (memory)       10    5.00s  5.72%   500ms     0.00B  0.00%    0.00B
 dual gap              10    2.40s  2.75%   240ms     0.00B  0.00%    0.00B
 ──────────────────────────────────────────────────────────────────────────</code></pre><p>The above is the optional benchmarking of the oracles that we provide to understand how fast crucial parts of the algorithms are, mostly notably oracle evaluations, the update of the iterate and the computation of the dual gap. As you can see if you compare <code>update (blas)</code> vs. <code>update (memory)</code>, the normal update when we use BLAS requires an additional 14.9GB of memory on top of the gradient etc whereas the <code>update (memory)</code> (the memory emphasis mode) does not consume any extra memory. This is also reflected in the computational times: the BLAS version requires 3.61 seconds on average to update the iterate, while the memory emphasis version requires only 500ms. In fact none of the crucial components in the algorithm consume any memory when run in memory efficient mode. Now let us look at the actual footprint of the whole algorithm:</p><pre><code class="nohighlight hljs">Vanilla Frank-Wolfe Algorithm.
EMPHASIS: memory STEPSIZE: agnostic EPSILON: 1.0e-7 MAXITERATION: 1000 TYPE: Float64
MOMENTUM: nothing GRADIENTTYPE: Nothing
WARNING: In memory emphasis mode iterates are written back into x0!

─────────────────────────────────────────────────────────────────────────────────────────────────
  Type     Iteration         Primal           Dual       Dual Gap           Time         It/sec
─────────────────────────────────────────────────────────────────────────────────────────────────
     I             0   1.000000e+00  -1.000000e+00   2.000000e+00   8.783523e+00   0.000000e+00
    FW           100   1.326732e-02  -1.326733e-02   2.653465e-02   4.635923e+02   2.157068e-01
    FW           200   6.650080e-03  -6.650086e-03   1.330017e-02   9.181294e+02   2.178342e-01
    FW           300   4.437059e-03  -4.437064e-03   8.874123e-03   1.372615e+03   2.185609e-01
    FW           400   3.329174e-03  -3.329180e-03   6.658354e-03   1.827260e+03   2.189070e-01
    FW           500   2.664003e-03  -2.664008e-03   5.328011e-03   2.281865e+03   2.191190e-01
    FW           600   2.220371e-03  -2.220376e-03   4.440747e-03   2.736387e+03   2.192672e-01
    FW           700   1.903401e-03  -1.903406e-03   3.806807e-03   3.190951e+03   2.193703e-01
    FW           800   1.665624e-03  -1.665629e-03   3.331253e-03   3.645425e+03   2.194532e-01
    FW           900   1.480657e-03  -1.480662e-03   2.961319e-03   4.099931e+03   2.195159e-01
    FW          1000   1.332665e-03  -1.332670e-03   2.665335e-03   4.554703e+03   2.195533e-01
  Last          1000   1.331334e-03  -1.331339e-03   2.662673e-03   4.559822e+03   2.195261e-01
─────────────────────────────────────────────────────────────────────────────────────────────────

4560.661203 seconds (7.41 M allocations: 112.121 GiB, 0.01% gc time)</code></pre><p>As you can see the algorithm ran for about 4600 secs (single-thread run) allocating 112.121 GiB of memory throughout. So how does this average out to the per-iteration cost in terms of memory: <code>112.121 / 7.45 / 1000 = 0.0151</code> so about 15.1MiB per iteration which is much less than the size of the gradient and in fact only stems from the reporting here.</p><p><strong>NB.</strong> This example highlights also one of the great features of first-order methods and conditional gradients in particular: we have dimension-independent convergence rates. In fact, we contract the primal gap as <code>2LD^2 / (t+2)</code> (for the simple agnostic rule) and, e.g., if the feasible region is the probability simplex with <code>D = sqrt(2)</code> and the function has bounded Lipschitzness, e.g., the function <code>|| x - xp ||^2</code> has <code>L = 2</code>, then the convergence rate is completely independent of the input size. The only thing that limits scaling is how much memory you have available and whether you can stomach the (linear) per-iteration cost.</p><h2 id="Iterate-and-atom-expected-interface"><a class="docs-heading-anchor" href="#Iterate-and-atom-expected-interface">Iterate and atom expected interface</a><a id="Iterate-and-atom-expected-interface-1"></a><a class="docs-heading-anchor-permalink" href="#Iterate-and-atom-expected-interface" title="Permalink"></a></h2><p>Frank-Wolfe can work on iterate beyond plain vectors, for example with any array-like object. Broadly speaking, the iterate type is assumed to behave as the member of a Hilbert space and optionally be mutable. Assuming the iterate type is <code>IT</code>, some methods must be implemented, with their usual semantics:</p><pre><code class="language-julia hljs">Base.similar(::IT)
Base.similar(::IT, ::Type{T})
Base.eltype(::IT)
Base.copy(::IT)

Base.:+(x1::IT, x2::IT)
Base.:*(scalar::Real, x::IT)
Base.:-(x1::IT, x2::IT)
LinearAlgebra.dot(x1::IT, x2::IT)</code></pre><p>For methods using an <a href="../reference/#FrankWolfe.ActiveSet"><code>FrankWolfe.ActiveSet</code></a>, the atoms or individual extreme points of the feasible region are not necessarily of the same type as the iterate. They are assumed to be immutable, must implement <code>LinearAlgebra.dot</code> with a gradient object. See for example <a href="../reference/#FrankWolfe.RankOneMatrix"><code>FrankWolfe.RankOneMatrix</code></a> or <a href="../reference/#FrankWolfe.ScaledHotVector"><code>FrankWolfe.ScaledHotVector</code></a>.</p><p>The iterate type <code>IT</code> must be a broadcastable mutable object or implement <a href="@ref"><code>FrankWolfe.compute_active_set_iterate!</code></a>:</p><pre><code class="language-julia hljs">FrankWolfe.compute_active_set_iterate!(active_set::FrankWolfe.ActiveSet{AT, R, IT}) where {AT, R}</code></pre><p>which recomputes the iterate from the current convex decomposition and the following methods <a href="../reference/#FrankWolfe.active_set_update_scale!-Union{Tuple{IT}, Tuple{IT, Any, Any}} where IT"><code>FrankWolfe.active_set_update_scale!</code></a> and <a href="../reference/#FrankWolfe.active_set_update_iterate_pairwise!-Union{Tuple{IT}, Tuple{IT, Any, Any, Any}} where IT"><code>FrankWolfe.active_set_update_iterate_pairwise!</code></a>:</p><pre><code class="language-julia hljs">FrankWolfe.active_set_update_scale!(x::IT, lambda, atom)
FrankWolfe.active_set_update_iterate_pairwise!(x::IT, lambda, fw_atom, away_atom)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../basics/">« How does it work?</a><a class="docs-footer-nextpage" href="../examples/docs_0_fw_visualized/">Visualization of Frank-Wolfe running on a 2-dimensional polytope »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.20 on <span class="colophon-date" title="Monday 11 July 2022 16:11">Monday 11 July 2022</span>. Using Julia version 1.6.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
